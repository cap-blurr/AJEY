// Server-only Gemini wrapper using the official SDK (@google/genai)
// Docs (JS quickstart): https://ai.google.dev/gemini-api/docs/quickstart

import { GoogleGenAI, Type } from "@google/genai";
import { executeAllocation } from "@/lib/agents/workflow";

export type GeminiPlanRequest = {
  kind: "deposit" | "pod_proposal";
  payload: Record<string, unknown>;
};

export type GeminiPlanResponse = {
  rationale: string;
  plan: Record<string, unknown>;
  thoughts?: string[];
  usage?: { thoughtsTokenCount?: number; candidatesTokenCount?: number };
};

// Models by role
const WORKFLOW_MODEL = process.env.GEMINI_MODEL || "gemini-2.5-flash";
const REASONING_MODEL = process.env.GEMINI_REASONING_MODEL || "gemini-2.5-pro";

function getClient() {
  if (typeof window !== "undefined") throw new Error("Gemini must run server-side");
  // The SDK automatically reads GEMINI_API_KEY from env per docs
  return new GoogleGenAI({});
}

// Tool calling and direct on-chain actions are disabled for the reasoning agent.

export async function generatePlan(
  request: GeminiPlanRequest,
  options?: { model?: string; allowOnchain?: boolean },
): Promise<GeminiPlanResponse> {
  const ai = getClient();

  const system =
    "You are a workflow planner and executor for DeFi vault operations. " +
    "Prefer making explicit, minimal plans. Use available tools only when parameters are clear.";

  const user =
    `Task: ${request.kind}.\n` +
    `Input: ${JSON.stringify(request.payload)}\n` +
    "Return a short 'rationale'. If tool use is appropriate, call the function with exact arguments.";

  const model = options?.model || WORKFLOW_MODEL;
  const prompt = `${system}\n\n${user}`;
  const config: any = { temperature: 0.2 };
  // Provide dynamic/default thinking for flash model per docs
  if (model.includes("flash")) {
    (config as any).thinkingConfig = { thinkingBudget: -1 };
  }

  const params: any = {
    model,
    contents: prompt,
    config,
  };
  // Expose a single workflow tool for function calling (opt-in execution)
  const tools = [
    {
      functionDeclarations: [
        {
          name: "allocateToVault",
          description: "Allocates WETH from the Ajey Vault to Aave by calling supplyToAave(amountWei).",
          parameters: {
            type: "object",
            properties: {
              amountWei: { type: "string", description: "Amount in wei to supply (stringified bigint)" },
              dryRun: { type: "boolean", description: "If true, don't broadcast on-chain" },
            },
            required: ["amountWei"],
          },
        },
      ],
    },
  ];
  (params as any).tools = tools;

  const response: any = await ai.models.generateContent(params);

  const rationale: string = response?.text || "Generated by Gemini";
  const thoughts: string[] = [];
  try {
    const parts = response?.candidates?.[0]?.content?.parts || [];
    for (const p of parts) {
      if (p?.thought && typeof p.text === "string") thoughts.push(p.text);
    }
  } catch {}
  const usage = {
    thoughtsTokenCount: response?.usageMetadata?.thoughtsTokenCount,
    candidatesTokenCount: response?.usageMetadata?.candidatesTokenCount,
  };

  // Extract potential function calls
  const calls: Array<{ name: string; args: Record<string, unknown> }> = [];
  try {
    const parts = response?.candidates?.[0]?.content?.parts || [];
    for (const p of parts) {
      if (p?.functionCall?.name) {
        calls.push({ name: p.functionCall.name, args: p.functionCall.args || {} });
      }
    }
  } catch {}

  const results: Array<{ name: string; args: any; result?: unknown }> = [];
  const canExecute = options?.allowOnchain && process.env.AGENT_ALLOW_ONCHAIN === "true";
  for (const call of calls) {
    if (call.name === "allocateToVault") {
      const { amountWei, dryRun } = call.args as any;
      if (canExecute && !dryRun) {
        const res = await executeAllocation({ amountWei: String(amountWei) });
        results.push({ name: call.name, args: call.args, result: res });
      } else {
        results.push({ name: call.name, args: call.args, result: { dryRun: true } });
      }
    }
  }

  return {
    rationale,
    plan: { action: request.kind, input: request.payload, results },
    thoughts,
    usage,
  };
}

// Reasoning-agent specific entrypoint using the pro model by default
export async function generateReasoningPlan(
  request: GeminiPlanRequest,
  options?: { model?: string; allowOnchain?: boolean },
): Promise<GeminiPlanResponse> {
  const ai = getClient();

  // Build a strict JSON-only envelope with explicit instructions and inputs
  const model = options?.model || REASONING_MODEL;
  const instructionsPreset = {
    version: 1,
    objective:
      "Propose a single target allocation plan for WETH supply-only (no borrowing) on Base Sepolia.",
    policy: {
      filter: { requireActive: true, requireNotFrozen: true, minAvailableUSD: "0" },
      rank: ["supplyAprPercent desc", "availableUSD desc", "tvlUSD desc"],
      constraints: [
        "Only consider supplyAprPercent; ignore borrow-related metrics.",
        "Require availableUSD > 0 and capacity headroom if capped.",
        "Proposed amountWei must be <= vault.idleWei and within supply cap headroom.",
        "Vault asset is WETH; pool selection is fixed and does not require an address.",
        "Use ETH increments >= 0.0001 ETH. Round down to the nearest 0.0001 ETH when converting to wei.",
      ],
    },
    outputSpec: {
      rankingFields: [
        "asset",
        "symbol",
        "supplyAprPercent",
        "availableUSD",
        "tvlUSD",
        "capacityHeadroomUSD",
      ],
      planFields: ["action", "amountWei", "thinkingSummary"],
    },
  };
  const envelope = {
    instructions: instructionsPreset,
    inputs: request.payload,
  };
  const prompt = JSON.stringify(envelope);
  const config: any = {
    temperature: 0,
    responseMimeType: "application/json",
    responseSchema: {
      type: Type.OBJECT,
      properties: {
        rationale: { type: Type.STRING },
        thinkingSummary: { type: Type.STRING },
        ranking: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              asset: { type: Type.STRING },
              symbol: { type: Type.STRING },
              supplyAprPercent: { type: Type.NUMBER },
              availableUSD: { type: Type.STRING },
              tvlUSD: { type: Type.STRING },
              capacityHeadroomUSD: { type: Type.STRING },
            },
            required: ["asset", "symbol", "supplyAprPercent"],
          },
        },
        plan: {
          type: Type.OBJECT,
          properties: {
            action: { type: Type.STRING },
            amountWei: { type: Type.STRING },
            thinkingSummary: { type: Type.STRING },
          },
          propertyOrdering: ["action", "amountWei", "thinkingSummary"],
          required: ["action", "amountWei"],
        },
      },
      propertyOrdering: ["rationale", "thinkingSummary", "ranking", "plan"],
    },
  };
  // Enable maximum thinking budget on reasoning model (Gemini 2.5 pro)
  if (model.includes("2.5")) {
    (config as any).thinkingConfig = { thinkingBudget: 32768 };
  }

  const params: any = {
    model,
    contents: prompt,
    config,
  };

  const response: any = await ai.models.generateContent(params);
  // JS SDK: structured output available as JSON string in response.text per docs
  // https://ai.google.dev/gemini-api/docs/structured-output
  const raw = (response?.text as string) || "{}";
  let parsed: any = {};
  try {
    parsed = JSON.parse(raw);
  } catch {
    parsed = {};
  }
  const rationale: string = parsed?.rationale || "";
  const summaryFromSchema: string | undefined = parsed?.thinkingSummary || parsed?.plan?.thinkingSummary;
  const thoughts: string[] = [];
  try {
    const parts = response?.candidates?.[0]?.content?.parts || [];
    for (const p of parts) {
      if (p?.thought && typeof p.text === "string") thoughts.push(p.text);
    }
  } catch {}
  if ((!thoughts || thoughts.length === 0) && typeof summaryFromSchema === "string" && summaryFromSchema.length > 0) {
    thoughts.push(summaryFromSchema);
  }
  const usage = {
    thoughtsTokenCount: response?.usageMetadata?.thoughtsTokenCount,
    candidatesTokenCount: response?.usageMetadata?.candidatesTokenCount,
  };

  // Return the model's structured object as `plan` to downstream consumers
  const planObj = parsed && typeof parsed === "object" ? parsed : {};
  return {
    rationale,
    plan: planObj,
    thoughts,
    usage,
  };
}


